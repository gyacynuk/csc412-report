{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_CSC412_VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUKUk8gHqTzs"
      },
      "source": [
        "# Import and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNBJOaUzqb79"
      },
      "source": [
        "try:\n",
        "  import pypianoroll as ppr\n",
        "except ModuleNotFoundError:\n",
        "  !apt-get install fluidsynth\n",
        "  !pip install pyfluidsynth\n",
        "  !pip install pypianoroll\n",
        "  import pypianoroll as ppr\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.distributions import Normal\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import random\n",
        "from scipy.sparse import csc_matrix\n",
        "import scipy.io.wavfile\n",
        "from IPython.display import Audio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kUqQeVJvD5l"
      },
      "source": [
        "# Mount Google Drive to the filesystem.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPB8M8UN8kDz"
      },
      "source": [
        "# Definitions of model and training parameters.\n",
        "NUM_EPOCHS = 200\n",
        "BATCH_SIZE = 100\n",
        "SHUFFLE = True\n",
        "LATENT_DIM = 64\n",
        "ENC_HIDDEN_SIZE = 144\n",
        "DEC_HIDDEN_SIZE = 96\n",
        "\n",
        "# Take advantage of GPUs if available.\n",
        "GPU = False\n",
        "cuda = torch.device('cuda')\n",
        "cpu = torch.device('cpu')\n",
        "device = cuda if GPU else cpu"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsNdCNl5-lFb"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "listELw4qlcz"
      },
      "source": [
        "def load_data_from_npz(filename_format, num_train=10, num_valid=1):\n",
        "  \"\"\"Load and return the training data from several .npz files.\n",
        "    \n",
        "  Parameters\n",
        "  ----------\n",
        "  filename_format: str\n",
        "      Format string for the path to the .npz files.  Contains a single\n",
        "      placeholder for the partition number, e.g. '/path/to/data-{}.npz'\n",
        "  num_train: int\n",
        "      The number of partitions to use for training.\n",
        "  num_valid: int\n",
        "      The number of partitions to use for validation.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  (x_train, x_valid): tuple(np.array, np.array)\n",
        "      The training and validation datasets, as Numpy arrays.\n",
        "  \"\"\"\n",
        "  train_data = None\n",
        "  validation_data = None\n",
        "\n",
        "  # First `num_train` files are for training.  Final `num_valid` files are for\n",
        "  # validation.\n",
        "  for i in range(num_train + num_valid):\n",
        "    filename = filename_format.format(i)\n",
        "    with np.load(filename) as f:\n",
        "      dataset_shape = f['shape']\n",
        "\n",
        "      # Set array entries to -1 if no note, 1 otherwise.\n",
        "      data = -np.ones(dataset_shape, np.float32)\n",
        "      data[[x for x in f['nonzero']]] = 1\n",
        "\n",
        "      if i < num_train:\n",
        "        if train_data is None:\n",
        "          train_data = data\n",
        "        else:\n",
        "          # After the second iteration, concatenate the new data.\n",
        "          train_data = np.concatenate((train_data, data), axis=0)\n",
        "      else:\n",
        "        if validation_data is None:\n",
        "          validation_data = data\n",
        "        else:\n",
        "          # After the second iteration, concatenate the new data.\n",
        "          validation_data = np.concatenate((validation_data, data), axis=0)\n",
        "\n",
        "  num_train_examples = train_data.shape[0]\n",
        "  num_valid_examples = validation_data.shape[0]\n",
        "\n",
        "  # Remove parts of the piano roll matrices that don't contain notes.\n",
        "  train_data = train_data.reshape(num_train_examples, -1, 128)[:, :, 20:108].reshape(num_train_examples, -1)\n",
        "  validation_data = validation_data.reshape(num_valid_examples, -1, 128)[:, :, 20:108].reshape(num_valid_examples, -1)\n",
        "\n",
        "  x_train = torch.from_numpy(train_data).to(device)\n",
        "  x_valid = torch.from_numpy(validation_data).to(device)\n",
        "  return x_train, x_valid"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FxO6TrYqYg2"
      },
      "source": [
        "# Variational Auto Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zVCDF9dq0Tu"
      },
      "source": [
        "class VAE(nn.Module):\n",
        "  \"\"\"VAE model.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, latent_dim, input_size, enc_hidden_size, dec_hidden_size):\n",
        "    \"\"\"Initialize this VAE.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    latent_dim: int\n",
        "        The dimension of the VAE's latent space.\n",
        "    input_size: int\n",
        "        The size of the encoder input/decoder output (should be equal to the\n",
        "        number of timesteps multiplied by the number of pitches).\n",
        "    enc_hidden_size: int\n",
        "        The size of the encoder's hidden layer.\n",
        "    dec_hidden_size: int\n",
        "        The size of the decoder's hidden layer.\n",
        "    \"\"\"\n",
        "    super(VAE, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "    # The encoder has one hidden layer, batch normalization and a ReLU nonlinearity.\n",
        "    # It outputs mu and sigma, the parameters for the variational distribution.\n",
        "    self.encoder = nn.Sequential(\n",
        "                    nn.Linear(input_size, enc_hidden_size).to(device),\n",
        "                    nn.BatchNorm1d(enc_hidden_size).to(device),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(enc_hidden_size, 2*latent_dim).to(device)\n",
        "    )\n",
        "    \n",
        "    # The decoder has one hidden layer, batch normalization and a ReLU nonlinearity.\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(latent_dim, dec_hidden_size).to(device),\n",
        "        nn.BatchNorm1d(dec_hidden_size).to(device),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(dec_hidden_size, input_size).to(device)\n",
        "    )\n",
        "\n",
        "  def reparameterize(self, mu, log_sigma):\n",
        "    \"\"\"Performs the reparametrization trick.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    mu: torch.Tensor(latent_dim)\n",
        "        The mean of the variational distribution.\n",
        "    log_sigma: torch.tensor(latent_dim)\n",
        "        Log of the standard deviation of the variational distribution.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    transformed_samples\n",
        "        Samples from the variational distribution.\n",
        "    \"\"\"\n",
        "    eps = torch.randn(self.latent_dim).to(device)\n",
        "    return mu + torch.exp(log_sigma) * eps\n",
        "\n",
        "  def forward(self, batch):\n",
        "    \"\"\"Forward pass for the VAE.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    batch: torch.Tensor(batch_size, input_dim)\n",
        "        A batch of data.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    decoded: torch.Tensor(batch_size, input_dim)\n",
        "        The reconstruction of the input batch.\n",
        "    \"\"\"\n",
        "    # Pass the batch through the encoder to obtain the variational distribution\n",
        "    # parameters, mu and log_sigma.\n",
        "    encoded = self.encoder(batch)\n",
        "    params = torch.chunk(input = encoded, chunks=2, dim=1)\n",
        "    mu, log_sigma = params[0], params[1]\n",
        "\n",
        "    # Sample from the variational distribution.\n",
        "    sample = self.reparameterize(mu, log_sigma)\n",
        "\n",
        "    # Decode the variational distribution sample.\n",
        "    decoded = self.decoder(sample)\n",
        "\n",
        "    return decoded\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifv7pKknqyEx"
      },
      "source": [
        "# Plotting Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqJRaVV_xhth"
      },
      "source": [
        "def get_multitrack(pianoroll):\n",
        "    \"\"\"Converts a Numpy array pianoroll into a pypianoroll.Multitrack object.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pianoroll: np.array(num_timesteps, 128)\n",
        "        A Numpy boolean-valued matrix which defines the music.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    multitrack: pypianoroll.Multitrack\n",
        "        A multitrack containing the specified music.\n",
        "    \"\"\"\n",
        "\n",
        "    tracks = [\n",
        "            ppr.BinaryTrack(name='track',\n",
        "            program=1,\n",
        "            is_drum=False,\n",
        "            pianoroll=pianoroll\n",
        "          )\n",
        "    ]\n",
        "    multitrack = ppr.Multitrack(\n",
        "            name='multitrack',\n",
        "            resolution=24,\n",
        "            tracks=tracks\n",
        "          )\n",
        "    return multitrack"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltM39KmNqZ9-"
      },
      "source": [
        "def plot_pianoroll(pianoroll):\n",
        "    \"\"\"Plot a pianoroll for visualization.\n",
        "      \n",
        "    Parameters\n",
        "    ----------\n",
        "    pianoroll: np.array(num_timesteps, 128)\n",
        "        A Numpy boolean-valued matrix which defines the music.\n",
        "    \"\"\"\n",
        "    multitrack = get_multitrack(pianoroll)\n",
        "    ppr.plot(multitrack)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMqSBXyBrGog"
      },
      "source": [
        "def plot_model_reconstruction(model=None, model_filepath='/content/drive/MyDrive/models/model.pth'):\n",
        "    \"\"\"Plots the reconstruction of a random validation sample.\n",
        "      \n",
        "    Parameters\n",
        "    ----------\n",
        "    model: torch.nn.Module\n",
        "        PyTorch VAE model.\n",
        "    \"\"\"\n",
        "  \n",
        "    # If no model is specified, load one from a file.\n",
        "    if model is None:\n",
        "        model = loadModel(model_filepath, forInference=True)\n",
        "    else:\n",
        "        # We are using this model for inference.\n",
        "        model.eval()\n",
        "    \n",
        "    # Randomly select a validation example.\n",
        "    index = int(random.random() * validation_data.shape[0])\n",
        "    validation_example = validation_data[index]\n",
        "\n",
        "    # Plot the validation example as a pianoroll.\n",
        "    pianoroll = validation_example.reshape((96, -1)).to(cpu).numpy()\n",
        "    padded_zeroes = np.zeros((96, 20))\n",
        "    pianoroll = np.concatenate((padded_zeroes, pianoroll, padded_zeroes), axis=1)\n",
        "    pianoroll = pianoroll > 0\n",
        "    plot_pianoroll(pianoroll)\n",
        "\n",
        "    # Plot the reconstruction of the validation example as a pianoroll.\n",
        "    validation_example = validation_example.reshape(-1, validation_example.shape[0])\n",
        "    encoder_out = model.encoder(validation_example)\n",
        "    mean = torch.chunk(input=encoder_out, chunks=2, dim=1)[0]\n",
        "    out_pianoroll = model.decoder(mean).reshape((96, -1)).to(cpu).detach().numpy()\n",
        "    out_pianoroll = np.concatenate((padded_zeroes, out_pianoroll, padded_zeroes), axis=1)\n",
        "    out_pianoroll = out_pianoroll > 0\n",
        "    plot_pianoroll(out_pianoroll)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjfizTL1-Wbw"
      },
      "source": [
        "# Save and Load Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGZ0tCzm-VgR"
      },
      "source": [
        "def saveModel(path, model):\n",
        "  \"\"\"Save a model in its entirety\n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  path: str\n",
        "    The path to the file where the model should be saved\n",
        "  model: torch.nn.Module\n",
        "    The model to be saved\n",
        "  \"\"\"\n",
        "  torch.save(model, path)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtsMODfV-SJp"
      },
      "source": [
        "def loadModel(path, forInference=False):\n",
        "  \"\"\"Load a saved RevNet model\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  path: str\n",
        "    The path to the file where the model should be read from\n",
        "  forInference: bool, optional\n",
        "    Whether the model should be loaded specifically for inference or not\n",
        "  \n",
        "  Returns\n",
        "  -------\n",
        "  model: torch.nn.Module\n",
        "    The loaded model\n",
        "  \"\"\"\n",
        "  model = torch.load(path, map_location=device)\n",
        "  if forInference:\n",
        "    model.eval()\n",
        "  return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDUoysAf0Y4s"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq24gVXX_98Q"
      },
      "source": [
        "def neg_elbo_loss(model, batch, num_samples=20):\n",
        "    \"\"\"Computes and returns the ELBO loss of the specified batch.\n",
        "      \n",
        "    Parameters\n",
        "    ----------\n",
        "    model: torch.nn.Module\n",
        "        PyTorch VAE model.\n",
        "    batch: torch.Tensor(batch_size, input_dim)\n",
        "        A batch of data.\n",
        "    num_samples: int\n",
        "        The number of samples to take for computing the ELBO loss.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    elbo: float\n",
        "        Negative ELBO value for the current batch.\n",
        "    \"\"\"\n",
        "\n",
        "    # Pass the batch to the encoder to obtain the variational parameters.\n",
        "    params = model.encoder(batch)\n",
        "    params_split = torch.chunk(input = params, chunks=2, dim=1)\n",
        "    mu, log_sigma = params_split[0], params_split[1]\n",
        "\n",
        "    input_dim = batch.shape[1]\n",
        "    batch_size, latent_dim = mu.shape\n",
        "    samples = torch.randn(num_samples, batch_size, latent_dim).to(device)\n",
        "    q_samples = samples * torch.exp(log_sigma).expand_as(samples) + mu.expand_as(samples)\n",
        "    # Model posterior.\n",
        "    p_z = Normal(torch.zeros(mu.shape).to(device), torch.ones(mu.shape).to(device))\n",
        "    # Approximate variational distribution.\n",
        "    q_z = Normal(mu, torch.exp(log_sigma))\n",
        "\n",
        "    # Compute the KL Divergence Term of the ELBO loss.\n",
        "    kl_term = p_z.log_prob(q_samples) - q_z.log_prob(q_samples)\n",
        "\n",
        "    # Compute the Reconstruction Term of the ELBO loss.\n",
        "    x_hat = model.decoder(q_samples.reshape(-1, latent_dim)).reshape(num_samples, batch_size, input_dim)\n",
        "    p_x_z = Normal(x_hat, torch.ones(x_hat.shape).to(device))\n",
        "    reconstruction_term = p_x_z.log_prob(batch)\n",
        "\n",
        "    # Sum over the last dimension of each loss term, then compute the mean of\n",
        "    # each over the batch size and the number of samples.\n",
        "    elbo = torch.mean(kl_term.sum(-1)) + torch.mean(reconstruction_term.sum(-1))\n",
        "\n",
        "    return -elbo"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOeVMA-2seYj"
      },
      "source": [
        "def train(model, training_data, validation_data=None, epochs=20, bs=1, lr=0.02,\n",
        "              momentum=0.9, num_elbo_samples=20,\n",
        "              model_filepath='/content/drive/MyDrive/models/model.pth', verbose=False):\n",
        "    \"\"\"Train the VAE model.\n",
        "      \n",
        "    Parameters\n",
        "    ----------\n",
        "    model: torch.nn.Module\n",
        "        PyTorch VAE model.\n",
        "    training_data: torch.Tensor(train_size, input_dim)\n",
        "        The training dataset.\n",
        "    validation_data: torch.Tensor(validation_size, input_dim)\n",
        "        The validation dataset.\n",
        "    epochs: int\n",
        "        Number of epochs of training.\n",
        "    bs: int\n",
        "        Batch size.\n",
        "    lr: float\n",
        "        Learning rate.\n",
        "    momentum: float\n",
        "        momentum parameter for SGD.\n",
        "    verbose: bool\n",
        "        If True, print out extra information during training.\n",
        "    \"\"\"\n",
        "      \n",
        "    training_dataset = TensorDataset(training_data)\n",
        "    training_dataloader = DataLoader(training_dataset, batch_size=bs, shuffle=True)\n",
        "    validation_dataset = TensorDataset(validation_data)\n",
        "    validation_dataloader = DataLoader(validation_dataset, batch_size=bs, shuffle=False)\n",
        "\n",
        "    # Use stochastic gradient descent as an optimizer.\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    # Use learning rate annealing during training.\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
        "\n",
        "    all_losses = []\n",
        "    all_validation_losses = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        running_validation_loss = 0.0\n",
        "\n",
        "        for i, x in enumerate(training_dataloader):\n",
        "\n",
        "            x = x[0]\n",
        "            x.requires_grad = True\n",
        "\n",
        "            # Zero the parameter gradients.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward + backward + optimize.\n",
        "            loss = neg_elbo_loss(model, x, num_samples=num_elbo_samples)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Compute the current validation loss.\n",
        "        for i, x in enumerate(validation_dataloader):\n",
        "            x = x[0]\n",
        "            loss = neg_elbo_loss(model, x, num_samples=20)\n",
        "            running_validation_loss += loss.item()\n",
        "        all_validation_losses.append(running_validation_loss)\n",
        "\n",
        "        # If we have achieved the minimum validation loss seen so far, save the model.\n",
        "        if running_validation_loss == min(all_validation_losses):\n",
        "            print('Saving model on Epoch {}'.format(epoch + 1))\n",
        "            saveModel(model_filepath, model)\n",
        "        running_validation_loss = 0.0\n",
        "\n",
        "        # Anneal the learning rate.\n",
        "        scheduler.step(running_loss)\n",
        "\n",
        "        # Print loss at end of epoch.\n",
        "        if (verbose and (epoch+1) % 1 == 0) or epoch == epochs - 1:\n",
        "            print('[Epoch: %d] loss: %.3f' % (epoch + 1, running_loss * (bs / len(training_data))))\n",
        "        all_losses.append(running_loss)\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Plot the model's reconstruction of a validation example.\n",
        "        plot_model_reconstruction(model)\n",
        "\n",
        "    # Plot training losses.\n",
        "    plt.plot(list(range(epochs)), all_losses)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot validation losses.\n",
        "    plt.plot(list(range(epochs)), all_validation_losses)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Validation Loss')\n",
        "    plt.show()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABCPuyES84Ku"
      },
      "source": [
        "# Load the training and validation data.\n",
        "training_data, validation_data = load_data_from_npz('/content/drive/MyDrive/CSC412/data/dataset-{}.npz', num_train=10, num_valid=1)\n",
        "\n",
        "# Initialize our VAE model.\n",
        "model = VAE(latent_dim=LATENT_DIM, input_size=training_data.shape[1], enc_hidden_size=ENC_HIDDEN_SIZE, dec_hidden_size=DEC_HIDDEN_SIZE)\n",
        "\n",
        "# Train the model with the specified hyperparameters.\n",
        "train(model, training_data, validation_data=validation_data, epochs=NUM_EPOCHS, bs=BATCH_SIZE, lr=0.002, num_elbo_samples=20, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39T2q_Qb-ZMp"
      },
      "source": [
        "# Music Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44BZioEHdXWG"
      },
      "source": [
        "def plot_training_samples(training_data):\n",
        "    \"\"\"Plot a sample training example and create an audio listener for it.\n",
        "      \n",
        "    Parameters\n",
        "    ----------\n",
        "    training_data: torch.Tensor(train_size, input_dim)\n",
        "        The training dataset.\n",
        "    \"\"\"\n",
        "    # Choose a random training example and pad it above and below with zeroes.\n",
        "    sample_index = int(random.random() * training_data.shape[0])\n",
        "    training_sample = training_data[sample_index]\n",
        "    padded_zeroes = torch.zeros((96, 20))\n",
        "    curr_result = training_sample.reshape(96, 88)\n",
        "    curr_result = torch.cat((padded_zeroes, curr_result, padded_zeroes), dim=1)\n",
        "\n",
        "    # Convert this example to a boolean array.\n",
        "    binary_results = curr_result > 0\n",
        "\n",
        "    # Plot this example as a pianoroll.\n",
        "    plot_pianoroll(binary_results)\n",
        "\n",
        "    # Synthesize this MIDI data.\n",
        "    multitrack = get_multitrack(binary_results)\n",
        "    pm = multitrack.to_pretty_midi()\n",
        "    waveform = pm.fluidsynth()\n",
        "\n",
        "    # Output an audio listener within Colab.\n",
        "    Audio(waveform, rate=44100)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsTDMZU4bsnK"
      },
      "source": [
        "def write_to_npz_file(result, output_file):\n",
        "    \"\"\"Write a numpy array to an output file.\n",
        "      \n",
        "    Parameters\n",
        "    ----------\n",
        "    result: np.array\n",
        "        The array to write to a file.\n",
        "    output_file: str\n",
        "        The name of the output file.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert pianorolls to a boolean matrix, if necessary.\n",
        "    if result.dtype != np.bool:\n",
        "        result = (result > 0).astype(bool)\n",
        "      \n",
        "    assert output_file.endswith(\".npz\")\n",
        "    np.savez_compressed(\n",
        "        output_file,\n",
        "        data=result\n",
        "    )"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMOGWScWPFwK"
      },
      "source": [
        "def plot_sample_reconstruction(model_filepath='/content/drive/MyDrive/models/model.pth'):\n",
        "    \"\"\"Sample from the latent space, plot it, and create an audio player for it.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model_filepath: str\n",
        "        Path to the saved VAE model weights.\n",
        "    \"\"\"\n",
        "    num_samples = 1\n",
        "    padded_zeroes = torch.zeros((96, 20))\n",
        "    model = loadModel(model_filepath, forInference=True)\n",
        "    latent_samples = torch.randn(num_samples, LATENT_DIM).to(device)\n",
        "    results = model.decoder(latent_samples).to(cpu).detach()\n",
        "    \n",
        "    curr_result = results.reshape(96, 88)\n",
        "    curr_result = torch.cat((padded_zeroes, curr_result, padded_zeroes), dim=1)\n",
        "    binary_results = curr_result > 0\n",
        "    return binary_results\n",
        "\n",
        "    # Plot this example as a pianoroll.\n",
        "    plot_pianoroll(binary_results)\n",
        "\n",
        "    # Synthesize this MIDI data.\n",
        "    multitrack = get_multitrack(binary_results)\n",
        "    pm = multitrack.to_pretty_midi()\n",
        "    waveform = pm.fluidsynth()\n",
        "\n",
        "    # Output an audio listener within Colab.\n",
        "    Audio(waveform, rate=44100)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kM6w5E8MpTP"
      },
      "source": [
        "def find_closest_training_sample(generated_example, training_dataset):\n",
        "    \"\"\"Find the smallest distance between this sample and a training sample.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    generated_example: torch.Tensor(input_dim)\n",
        "        A sample generated from the model.\n",
        "    training_dataset: torch.Tensor(train_size, input_dim)\n",
        "        The training dataset.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "    # Find the distances between this sample and every training example.\n",
        "    sample_expanded = generated_example.expand(training_data.shape[0], -1)\n",
        "    dists = torch.linalg.norm(sample_expanded - training_data, ord=None, dim=1)\n",
        "\n",
        "    # Obtain the minimal distance track.\n",
        "    padded_zeroes = torch.zeros((96, 20))\n",
        "    min_dist, min_dist_index = torch.min(dists, dim=0)\n",
        "    min_dist_track = training_data[min_dist_index]\n",
        "    min_dist_track = min_dist_track.reshape(-1, 88)\n",
        "    min_dist_track = torch.cat((padded_zeroes, min_dist_track, padded_zeroes), dim=1)\n",
        "    binary_min_dist_track = min_dist_track > 0\n",
        "\n",
        "    return binary_min_dist_track"
      ],
      "execution_count": 53,
      "outputs": []
    }
  ]
}